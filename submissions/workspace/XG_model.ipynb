{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model Training for Production Prediction\n",
    "\n",
    "This section demonstrates how to train an XGBoost model on reservoir production data to predict oil, water, and gas production.\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Imports**:\n",
    "   - **`os` and `glob`**: Used to handle file paths and retrieve reservoir folders from the dataset.\n",
    "   - **`pandas`**: For data manipulation and loading datasets.\n",
    "   - **`xgboost`**: The XGBoost library is imported to build and train the model.\n",
    "   - **`train_test_split`**: Splits the dataset into training and testing sets.\n",
    "   - **`mean_squared_error`, `mean_absolute_error`, `r2_score`**: Metrics to evaluate model performance.\n",
    "\n",
    "2. **Training the XGBoost Model**:\n",
    "   - After data preprocessing and splitting the data into training and testing sets, the XGBoost model is trained to predict oil, water, and gas production using production and rock characteristic features.\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - After training, the model is evaluated using common regression metrics, such as:\n",
    "     - **Mean Squared Error (MSE)**: Measures the average squared difference between actual and predicted values.\n",
    "     - **Mean Absolute Error (MAE)**: Measures the average absolute difference between actual and predicted values.\n",
    "     - **RÂ² Score**: Evaluates how well the model fits the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Status and Production Data for Multiple Reservoirs\n",
    "\n",
    "This code combines the status (rock characteristics) and production (day-by-day production) data from multiple reservoirs into two consolidated DataFrames for further model training or analysis.\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Initializing DataFrames**:\n",
    "   - Empty lists (`all_status_dfs` and `all_production_dfs`) are initialized to store the status and production DataFrames for each reservoir.\n",
    "\n",
    "2. **Retrieving Reservoir Folders**:\n",
    "   - Using the `glob` module, the code retrieves paths to all reservoir folders from the dataset.\n",
    "\n",
    "3. **Loading and Processing Data**:\n",
    "   - For each reservoir:\n",
    "     - The paths to the `state.csv` (status data) and `production.csv` (production data) files are generated.\n",
    "     - Both datasets are loaded into DataFrames if the corresponding files exist.\n",
    "     - The production data is grouped by the `Date` column, and mean values are computed for each day.\n",
    "     - The `day` column is reset to start from 1 for each reservoir, representing sequential days.\n",
    "     - A `reservoir_id` column is added to both the status and production DataFrames to track the reservoir source.\n",
    "     - The `Date` column is dropped from the production data after processing.\n",
    "\n",
    "4. **Combining Data**:\n",
    "   - All individual status and production DataFrames are concatenated into two combined DataFrames (`combined_status_df` and `combined_production_df`).\n",
    "   - These combined DataFrames contain all the data from multiple reservoirs.\n",
    "\n",
    "5. **Saving Data**:\n",
    "   - The combined DataFrames are saved to CSV files (`combined_state.csv` and `combined_production.csv`) for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store DataFrames\n",
    "all_status_dfs = []\n",
    "all_production_dfs = []\n",
    "\n",
    "# Get all reservoir folders\n",
    "reservoir_folders = glob.glob(os.path.join('../../dataset/training', 'Reservoir*'))\n",
    "\n",
    "# Loop through each reservoir folder\n",
    "for reservoir_folder in reservoir_folders:\n",
    "    # Extract reservoir_id from folder name\n",
    "    reservoir_id = os.path.basename(reservoir_folder)\n",
    "\n",
    "    # Define paths to state and production files\n",
    "    state_path = os.path.join(reservoir_folder, 'state.csv')\n",
    "    production_path = os.path.join(reservoir_folder, 'production.csv')\n",
    "    \n",
    "    # Check if the state and production files exist\n",
    "    if os.path.exists(state_path) and os.path.exists(production_path):\n",
    "        # Load the datasets\n",
    "        status_df = pd.read_csv(state_path)\n",
    "        production_df = pd.read_csv(production_path)\n",
    "\n",
    "        # Group production data by 'Date' and compute mean values\n",
    "        production_df = production_df.groupby(['Date']).mean().reset_index()\n",
    "\n",
    "        # Reset the 'day' column starting from 1 for each reservoir\n",
    "        production_df['day'] = range(1, len(production_df) + 1)\n",
    "        \n",
    "        # Add reservoir_id column to both datasets\n",
    "        status_df['reservoir_id'] = reservoir_id\n",
    "        production_df['reservoir_id'] = reservoir_id\n",
    "        \n",
    "        # Drop the 'Date' column from the production data\n",
    "        production_df = production_df.drop(columns=['Date'])\n",
    "        \n",
    "        # Append DataFrames to lists\n",
    "        all_status_dfs.append(status_df)\n",
    "        all_production_dfs.append(production_df)\n",
    "\n",
    "# Concatenate all status and production DataFrames\n",
    "combined_status_df = pd.concat(all_status_dfs, ignore_index=True)\n",
    "combined_production_df = pd.concat(all_production_dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrames to CSV files\n",
    "combined_status_df.to_csv('preprocess_data/combined_train_state.csv', index=False)\n",
    "combined_production_df.to_csv('preprocess_data/combined_train_production.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reloading and Merging Combined Datasets\n",
    "\n",
    "This section of the code reloads the previously saved combined datasets, aggregates the status data, and merges it with the production data.\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Reload Combined Datasets**:\n",
    "   - The combined status data (`combined_state.csv`) and production data (`combined_production.csv`) are reloaded into DataFrames (`status_df` and `production_df`).\n",
    "\n",
    "2. **Aggregate Status Data**:\n",
    "   - The status data is aggregated by `reservoir_id` to compute the mean values of the following columns:\n",
    "     - **X**\n",
    "     - **Y**\n",
    "     - **Depth**\n",
    "     - **PERMX** (permeability in X direction)\n",
    "     - **PERMY** (permeability in Y direction)\n",
    "     - **PERMZ** (permeability in Z direction)\n",
    "     - **PORO** (porosity)\n",
    "     - **Transmissibility**\n",
    "   - The aggregation is done using the `agg()` function, which computes the mean of each column for each reservoir. The aggregated data is stored in `status_df_agg`.\n",
    "\n",
    "3. **Merge Aggregated Status Data with Production Data**:\n",
    "   - The aggregated status data (`status_df_agg`) is merged with the production data (`production_df`) based on the `reservoir_id`.\n",
    "   - This merge is performed using a left join, ensuring that all rows from the production data are preserved, and relevant status data is added where available.\n",
    "   - The result is stored in `combined_df`, which contains both the production data and the aggregated status data for each reservoir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the combined datasets\n",
    "status_df = pd.read_csv('preprocess_data/combined_state.csv')\n",
    "production_df = pd.read_csv('preprocess_data/combined_production.csv')\n",
    "\n",
    "# Aggregate status data by reservoir_id and compute mean values\n",
    "status_df_agg = status_df.groupby('reservoir_id').agg({\n",
    "    'X': 'mean',\n",
    "    'Y': 'mean',\n",
    "    'Depth': 'mean',\n",
    "    'PERMX': 'mean',\n",
    "    'PERMY': 'mean',\n",
    "    'PERMZ': 'mean',\n",
    "    'PORO': 'mean',\n",
    "    'Transmissibility': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge aggregated status data with production data on reservoir_id\n",
    "combined_df = pd.merge(production_df, status_df_agg, on='reservoir_id', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating the XGBoost Model\n",
    "\n",
    "This section prepares the data for model training, trains an XGBoost model, saves the model, and evaluates its performance.\n",
    "\n",
    "## Steps:\n",
    "\n",
    "1. **Prepare Features and Targets**:\n",
    "   - **Features (`X`)**: Includes columns related to reservoir rock characteristics and the `day` column from `combined_df`:\n",
    "     - **X**\n",
    "     - **Y**\n",
    "     - **Depth**\n",
    "     - **PERMX** (permeability in X direction)\n",
    "     - **PERMY** (permeability in Y direction)\n",
    "     - **PERMZ** (permeability in Z direction)\n",
    "     - **PORO** (porosity)\n",
    "     - **Transmissibility**\n",
    "     - **day**\n",
    "   - **Targets (`y`)**: Includes columns for cumulative production values:\n",
    "     - **Oil production cumulative**\n",
    "     - **Water production cumulative**\n",
    "     - **Gas production cumulative**\n",
    "\n",
    "2. **Split Data**:\n",
    "   - The data is split into training (80%) and testing (20%) sets using `train_test_split` with a random state for reproducibility.\n",
    "\n",
    "3. **Train XGBoost Model**:\n",
    "   - An XGBoost regressor (`xgb.XGBRegressor`) is instantiated with `objective='reg:squarederror'` to handle regression tasks.\n",
    "   - The model is trained on the training data (`X_train` and `y_train`).\n",
    "\n",
    "4. **Save the Model**:\n",
    "   - The trained model is saved to a file named `xgboost_model.json` for future use.\n",
    "\n",
    "5. **Make Predictions**:\n",
    "   - Predictions are made on the test set (`X_test`) using the trained model.\n",
    "\n",
    "6. **Calculate Metrics**:\n",
    "   - **Mean Squared Error (MSE)**: Measures the average squared difference between actual and predicted values.\n",
    "   - **Mean Absolute Error (MAE)**: Measures the average absolute difference between actual and predicted values.\n",
    "   - **RÂ² Score**: Evaluates how well the model fits the test data.\n",
    "   - These metrics are computed using `mean_squared_error`, `mean_absolute_error`, and `r2_score`, respectively.\n",
    "\n",
    "7. **Print Metrics**:\n",
    "   - The computed MSE, MAE, and RÂ² Score are printed to assess the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 96835819895.33015\n",
      "Mean Absolute Error: 183489.12765300297\n",
      "RÂ² Score: 0.9997407793998718\n"
     ]
    }
   ],
   "source": [
    "# Prepare features (X) and target (y)\n",
    "X = combined_df[['X', 'Y', 'Depth', 'PERMX', 'PERMY', 'PERMZ', 'PORO', 'Transmissibility', 'day']]\n",
    "y = combined_df[['Oil production cumulative', 'Water production cumulative', 'Gas production cumulative']]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "model.save_model('models/xgboost_model.json')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'RÂ² Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
